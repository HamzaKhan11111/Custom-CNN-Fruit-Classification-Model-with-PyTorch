{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread,imshow,imsave\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github\\Custom-CNN-Fruit-Classification-Model-with-PyTorch\\fruits-360-original-size\\fruits-360-original-size\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"fruits-360-original-size/fruits-360-original-size\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the following transformations to the given dataset using the torchvision transforms.Compose method:\n",
    "### a. Resize each image to 224x224 pixels\n",
    "### b. Apply image normalization with\n",
    "###      i. mean [0.485, 0.456, 0.406]\n",
    "###      ii. standard deviation [0.229, 0.224, 0.225]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Apply the following transformations to the given dataset using the torchvision\n",
    "transforms.Compose method:\n",
    "a. Resize each image to 224x224 pixels\n",
    "b. Apply image normalization with\n",
    "i. mean [0.485, 0.456, 0.406]\n",
    "ii. standard deviation [0.229, 0.224, 0.225] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "train = ImageFolder(root='Training', transform=transform)\n",
    "test = ImageFolder(root='Test', transform=transform)\n",
    "validation = ImageFolder(root='Validation', transform=transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom PyTorch model that includes the following layers:\n",
    "### a) 4 convolutional layers\n",
    "### b) 4 max pooling layers\n",
    "### c) 3 linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=16, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 53 * 53, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 131)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199: \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Github\\\\Custom-CNN-Fruit-Classification-Model-with-PyTorch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the model from Part 2 by adding two additional convolutional layers and two additional max pooling layers. Train this modified model using the same training set, and evaluate its performance on the same testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 4.591\n",
      "[2,   200] loss: 0.959\n",
      "[3,   200] loss: 0.413\n",
      "[4,   200] loss: 0.196\n",
      "[5,   200] loss: 0.132\n",
      "[6,   200] loss: 0.012\n",
      "[7,   200] loss: 0.001\n",
      "[8,   200] loss: 0.049\n",
      "[9,   200] loss: 0.005\n",
      "[10,   200] loss: 0.001\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=16,shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=16,shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(16, 32, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256 * 5 * 5, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(84, 131)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199: \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the accuracy and number of parameters between the original model and the modified model. Include the comparison in the report, along with three prediction results from each model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparasion is written in report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
